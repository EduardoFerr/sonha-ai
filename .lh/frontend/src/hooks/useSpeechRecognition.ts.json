{
    "sourceFile": "frontend/src/hooks/useSpeechRecognition.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 41,
            "patches": [
                {
                    "date": 1747763144666,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1747766263897,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,11 +106,20 @@\n         if (data.matches?.length) onTexto(data.matches[0])\r\n       })\r\n     } else {\r\n       try {\r\n+        const permissionStatus = await navigator.permissions?.query({\r\n+          name: 'microphone' as PermissionName,\r\n+        })\r\n+\r\n+        if (permissionStatus?.state === 'denied') {\r\n+          setErro('Permiss√£o de microfone negada pelo navegador. Verifique as configura√ß√µes do site.')\r\n+          return\r\n+        }\r\n+\r\n         recognitionRef.current?.start()\r\n       } catch (e) {\r\n-        setErro('Erro ao iniciar reconhecimento de voz.')\r\n+        setErro('Erro ao acessar o microfone. Verifique as permiss√µes do navegador.')\r\n       }\r\n     }\r\n \r\n     setGravando(true)\r\n"
                },
                {
                    "date": 1747766430455,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,18 +32,14 @@\n  * - Detecta plataforma automaticamente\r\n  * \r\n  * @param {UseSpeechRecognitionOptions} options - Op√ß√µes de configura√ß√£o, incluindo o callback `onTexto`\r\n  * @returns Um objeto com estado de grava√ß√£o, erros e fun√ß√µes para iniciar/parar o reconhecimento\r\n- * \r\n- * @example\r\n- * ```tsx\r\n- * const { gravando, start, stop, erro } = useSpeechRecognition({ onTexto: (t) => console.log(t) })\r\n- * ```\r\n  */\r\n export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n   const recognitionRef = useRef<any>(null)\r\n+  const gravandoRef = useRef(false)\r\n   const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n     if (platform === 'web') {\r\n@@ -69,9 +65,9 @@\n         setErro('Erro no reconhecimento de voz: ' + e.error)\r\n       }\r\n \r\n       recognition.onend = () => {\r\n-        if (recognitionRef.current && gravando) {\r\n+        if (recognitionRef.current && gravandoRef.current) {\r\n           recognitionRef.current.start()\r\n         }\r\n       }\r\n \r\n@@ -80,9 +76,9 @@\n \r\n     return () => {\r\n       recognitionRef.current?.stop?.()\r\n     }\r\n-  }, [platform, onTexto, gravando])\r\n+  }, [platform, onTexto])\r\n \r\n   /**\r\n    * Inicia o reconhecimento de voz com base na plataforma\r\n    */\r\n@@ -122,8 +118,9 @@\n       }\r\n     }\r\n \r\n     setGravando(true)\r\n+    gravandoRef.current = true\r\n   }\r\n \r\n   /**\r\n    * Encerra o reconhecimento de voz e limpa listeners\r\n@@ -136,8 +133,9 @@\n       recognitionRef.current?.stop?.()\r\n     }\r\n \r\n     setGravando(false)\r\n+    gravandoRef.current = false\r\n   }\r\n \r\n   return {\r\n     gravando,\r\n"
                },
                {
                    "date": 1747766845623,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,8 +42,9 @@\n   const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n     if (platform === 'web') {\r\n+      console.info('escultar no navegador 1')\r\n       const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n       if (!SpeechRecognitionClass) {\r\n         setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n         return\r\n"
                },
                {
                    "date": 1747766860541,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -83,8 +83,10 @@\n   /**\r\n    * Inicia o reconhecimento de voz com base na plataforma\r\n    */\r\n   const start = async () => {\r\n+    console.info('escultar no navegador - start')\r\n+\r\n     setErro(null)\r\n \r\n     if (platform === 'android' || platform === 'ios') {\r\n       const { speechRecognition } = await SpeechRecognition.requestPermissions()\r\n"
                },
                {
                    "date": 1747766870197,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -128,8 +128,10 @@\n   /**\r\n    * Encerra o reconhecimento de voz e limpa listeners\r\n    */\r\n   const stop = async () => {\r\n+    console.info('escultar no navegador - stop')\r\n+\r\n     if (platform === 'android' || platform === 'ios') {\r\n       await SpeechRecognition.stop()\r\n       await SpeechRecognition.removeAllListeners()\r\n     } else {\r\n"
                },
                {
                    "date": 1747767629400,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,7 @@\n import { useEffect, useRef, useState } from 'react'\r\n import { Capacitor } from '@capacitor/core'\r\n-import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n+import { SpeechRecognition, type SpeechRecognitionPlugin}  from '@capacitor-community/speech-recognition'\r\n \r\n /**\r\n  * Declara√ß√µes globais necess√°rias para usar a API Web Speech\r\n  */\r\n"
                },
                {
                    "date": 1747767804240,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,10 +1,10 @@\n import { useEffect, useRef, useState } from 'react'\r\n import { Capacitor } from '@capacitor/core'\r\n-import { SpeechRecognition, type SpeechRecognitionPlugin}  from '@capacitor-community/speech-recognition'\r\n+import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n \r\n /**\r\n- * Declara√ß√µes globais necess√°rias para usar a API Web Speech\r\n+ * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n  */\r\n declare global {\r\n   interface Window {\r\n     webkitSpeechRecognition: any\r\n@@ -17,23 +17,15 @@\n }\r\n \r\n /**\r\n  * Op√ß√µes do hook useSpeechRecognition\r\n- * @property onTexto - Fun√ß√£o chamada sempre que um novo trecho de texto for reconhecido\r\n  */\r\n-export interface UseSpeechRecognitionOptions {\r\n+interface UseSpeechRecognitionOptions {\r\n   onTexto: (texto: string) => void\r\n }\r\n \r\n /**\r\n- * Hook React para reconhecimento de voz multiplataforma (Web, Android, iOS).\r\n- * \r\n- * - Usa Web Speech API no navegador\r\n- * - Usa plugin do Capacitor em dispositivos m√≥veis\r\n- * - Detecta plataforma automaticamente\r\n- * \r\n- * @param {UseSpeechRecognitionOptions} options - Op√ß√µes de configura√ß√£o, incluindo o callback `onTexto`\r\n- * @returns Um objeto com estado de grava√ß√£o, erros e fun√ß√µes para iniciar/parar o reconhecimento\r\n+ * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n  */\r\n export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n@@ -42,9 +34,8 @@\n   const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n     if (platform === 'web') {\r\n-      console.info('escultar no navegador 1')\r\n       const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n       if (!SpeechRecognitionClass) {\r\n         setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n         return\r\n@@ -79,14 +70,9 @@\n       recognitionRef.current?.stop?.()\r\n     }\r\n   }, [platform, onTexto])\r\n \r\n-  /**\r\n-   * Inicia o reconhecimento de voz com base na plataforma\r\n-   */\r\n   const start = async () => {\r\n-    console.info('escultar no navegador - start')\r\n-\r\n     setErro(null)\r\n \r\n     if (platform === 'android' || platform === 'ios') {\r\n       const { speechRecognition } = await SpeechRecognition.requestPermissions()\r\n@@ -124,14 +110,9 @@\n     setGravando(true)\r\n     gravandoRef.current = true\r\n   }\r\n \r\n-  /**\r\n-   * Encerra o reconhecimento de voz e limpa listeners\r\n-   */\r\n   const stop = async () => {\r\n-    console.info('escultar no navegador - stop')\r\n-\r\n     if (platform === 'android' || platform === 'ios') {\r\n       await SpeechRecognition.stop()\r\n       await SpeechRecognition.removeAllListeners()\r\n     } else {\r\n"
                },
                {
                    "date": 1747767822339,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,7 @@\n import { useEffect, useRef, useState } from 'react'\r\n import { Capacitor } from '@capacitor/core'\r\n-import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n+import { SpeechRecognition,  type SpeechRecognitionPlugin} from '@capacitor-community/speech-recognition'\r\n \r\n /**\r\n  * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n  */\r\n"
                },
                {
                    "date": 1747767830888,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,7 @@\n import { useEffect, useRef, useState } from 'react'\r\n import { Capacitor } from '@capacitor/core'\r\n-import { SpeechRecognition,  type SpeechRecognitionPlugin} from '@capacitor-community/speech-recognition'\r\n+import { SpeechRecognition} from '@capacitor-community/speech-recognition'\r\n \r\n /**\r\n  * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n  */\r\n"
                },
                {
                    "date": 1747772797456,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,7 @@\n import { useEffect, useRef, useState } from 'react'\r\n import { Capacitor } from '@capacitor/core'\r\n-import { SpeechRecognition} from '@capacitor-community/speech-recognition'\r\n+import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n \r\n /**\r\n  * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n  */\r\n@@ -30,8 +30,9 @@\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n   const recognitionRef = useRef<any>(null)\r\n   const gravandoRef = useRef(false)\r\n+  const partialListenerRef = useRef<any>(null)\r\n   const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n     if (platform === 'web') {\r\n@@ -86,11 +87,21 @@\n         partialResults: true,\r\n         popup: false,\r\n       })\r\n \r\n-      SpeechRecognition.addListener('partialResults', (data: { matches: string[] }) => {\r\n-        if (data.matches?.length) onTexto(data.matches[0])\r\n-      })\r\n+      // Remove listener anterior, se existir\r\n+      if (partialListenerRef.current) {\r\n+        await partialListenerRef.current.remove()\r\n+        partialListenerRef.current = null\r\n+      }\r\n+\r\n+      // Adiciona novo listener e salva refer√™ncia\r\n+      partialListenerRef.current = await SpeechRecognition.addListener(\r\n+        'partialResults',\r\n+        (data: { matches: string[] }) => {\r\n+          if (data.matches?.length) onTexto(data.matches[0])\r\n+        }\r\n+      )\r\n     } else {\r\n       try {\r\n         const permissionStatus = await navigator.permissions?.query({\r\n           name: 'microphone' as PermissionName,\r\n@@ -113,8 +124,14 @@\n \r\n   const stop = async () => {\r\n     if (platform === 'android' || platform === 'ios') {\r\n       await SpeechRecognition.stop()\r\n+\r\n+      if (partialListenerRef.current) {\r\n+        await partialListenerRef.current.remove()\r\n+        partialListenerRef.current = null\r\n+      }\r\n+\r\n       await SpeechRecognition.removeAllListeners()\r\n     } else {\r\n       recognitionRef.current?.stop?.()\r\n     }\r\n"
                },
                {
                    "date": 1747773726488,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,149 +1,37 @@\n-import { useEffect, useRef, useState } from 'react'\r\n-import { Capacitor } from '@capacitor/core'\r\n-import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n-\r\n-/**\r\n- * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n- */\r\n-declare global {\r\n-  interface Window {\r\n-    webkitSpeechRecognition: any\r\n-    SpeechRecognition: any\r\n-  }\r\n-\r\n-  interface SpeechRecognitionEvent extends Event {\r\n-    readonly results: SpeechRecognitionResultList\r\n-  }\r\n-}\r\n-\r\n-/**\r\n- * Op√ß√µes do hook useSpeechRecognition\r\n- */\r\n-interface UseSpeechRecognitionOptions {\r\n-  onTexto: (texto: string) => void\r\n-}\r\n-\r\n-/**\r\n- * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n- */\r\n-export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n+export function useSpeechRecognition({ onTexto }: { onTexto: (texto: string) => void }) {\r\n   const [gravando, setGravando] = useState(false)\r\n-  const [erro, setErro] = useState<string | null>(null)\r\n   const recognitionRef = useRef<any>(null)\r\n-  const gravandoRef = useRef(false)\r\n-  const partialListenerRef = useRef<any>(null)\r\n-  const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n-    if (platform === 'web') {\r\n-      const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n-      if (!SpeechRecognitionClass) {\r\n-        setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n-        return\r\n-      }\r\n+    const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n+    if (!SpeechRecognitionClass) return\r\n \r\n-      const recognition = new SpeechRecognitionClass()\r\n-      recognition.lang = 'pt-BR'\r\n-      recognition.continuous = true\r\n-      recognition.interimResults = true\r\n+    const recognition = new SpeechRecognitionClass()\r\n+    recognition.lang = 'pt-BR'\r\n+    recognition.continuous = true\r\n+    recognition.interimResults = true\r\n \r\n-      recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-        const texto = Array.from(e.results)\r\n-          .map((r) => r[0].transcript)\r\n-          .join(' ')\r\n-        onTexto(texto)\r\n-      }\r\n-\r\n-      recognition.onerror = (e: any) => {\r\n-        setErro('Erro no reconhecimento de voz: ' + e.error)\r\n-      }\r\n-\r\n-      recognition.onend = () => {\r\n-        if (recognitionRef.current && gravandoRef.current) {\r\n-          recognitionRef.current.start()\r\n-        }\r\n-      }\r\n-\r\n-      recognitionRef.current = recognition\r\n+    recognition.onresult = (e: any) => {\r\n+      const texto = Array.from(e.results).map(r => r[0].transcript).join(' ')\r\n+      onTexto(texto) // üîÅ sempre substitui\r\n     }\r\n \r\n-    return () => {\r\n-      recognitionRef.current?.stop?.()\r\n-    }\r\n-  }, [platform, onTexto])\r\n+    recognitionRef.current = recognition\r\n+  }, [onTexto])\r\n \r\n-  const start = async () => {\r\n-    setErro(null)\r\n-\r\n-    if (platform === 'android' || platform === 'ios') {\r\n-      const { speechRecognition } = await SpeechRecognition.requestPermissions()\r\n-      if (speechRecognition !== 'granted') {\r\n-        setErro('Permiss√£o negada para usar o microfone.')\r\n-        return\r\n-      }\r\n-\r\n-      await SpeechRecognition.start({\r\n-        language: 'pt-BR',\r\n-        partialResults: true,\r\n-        popup: false,\r\n-      })\r\n-\r\n-      // Remove listener anterior, se existir\r\n-      if (partialListenerRef.current) {\r\n-        await partialListenerRef.current.remove()\r\n-        partialListenerRef.current = null\r\n-      }\r\n-\r\n-      // Adiciona novo listener e salva refer√™ncia\r\n-      partialListenerRef.current = await SpeechRecognition.addListener(\r\n-        'partialResults',\r\n-        (data: { matches: string[] }) => {\r\n-          if (data.matches?.length) onTexto(data.matches[0])\r\n-        }\r\n-      )\r\n-    } else {\r\n-      try {\r\n-        const permissionStatus = await navigator.permissions?.query({\r\n-          name: 'microphone' as PermissionName,\r\n-        })\r\n-\r\n-        if (permissionStatus?.state === 'denied') {\r\n-          setErro('Permiss√£o de microfone negada pelo navegador. Verifique as configura√ß√µes do site.')\r\n-          return\r\n-        }\r\n-\r\n-        recognitionRef.current?.start()\r\n-      } catch (e) {\r\n-        setErro('Erro ao acessar o microfone. Verifique as permiss√µes do navegador.')\r\n-      }\r\n-    }\r\n-\r\n+  const start = () => {\r\n+    recognitionRef.current?.start()\r\n     setGravando(true)\r\n-    gravandoRef.current = true\r\n   }\r\n \r\n-  const stop = async () => {\r\n-    if (platform === 'android' || platform === 'ios') {\r\n-      await SpeechRecognition.stop()\r\n-\r\n-      if (partialListenerRef.current) {\r\n-        await partialListenerRef.current.remove()\r\n-        partialListenerRef.current = null\r\n-      }\r\n-\r\n-      await SpeechRecognition.removeAllListeners()\r\n-    } else {\r\n-      recognitionRef.current?.stop?.()\r\n-    }\r\n-\r\n+  const stop = () => {\r\n+    recognitionRef.current?.stop()\r\n     setGravando(false)\r\n-    gravandoRef.current = false\r\n   }\r\n \r\n   return {\r\n     gravando,\r\n-    erro,\r\n     start,\r\n-    stop,\r\n+    stop\r\n   }\r\n }\r\n"
                },
                {
                    "date": 1747773754192,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,37 +1,149 @@\n-export function useSpeechRecognition({ onTexto }: { onTexto: (texto: string) => void }) {\r\n+import { useEffect, useRef, useState } from 'react'\r\n+import { Capacitor } from '@capacitor/core'\r\n+import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n+\r\n+/**\r\n+ * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n+ */\r\n+declare global {\r\n+  interface Window {\r\n+    webkitSpeechRecognition: any\r\n+    SpeechRecognition: any\r\n+  }\r\n+\r\n+  interface SpeechRecognitionEvent extends Event {\r\n+    readonly results: SpeechRecognitionResultList\r\n+  }\r\n+}\r\n+\r\n+/**\r\n+ * Op√ß√µes do hook useSpeechRecognition\r\n+ */\r\n+interface UseSpeechRecognitionOptions {\r\n+  onTexto: (texto: string) => void\r\n+}\r\n+\r\n+/**\r\n+ * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n+ */\r\n+export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n   const [gravando, setGravando] = useState(false)\r\n+  const [erro, setErro] = useState<string | null>(null)\r\n   const recognitionRef = useRef<any>(null)\r\n+  const gravandoRef = useRef(false)\r\n+  const partialListenerRef = useRef<any>(null)\r\n+  const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n-    const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n-    if (!SpeechRecognitionClass) return\r\n+    if (platform === 'web') {\r\n+      const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n+      if (!SpeechRecognitionClass) {\r\n+        setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n+        return\r\n+      }\r\n \r\n-    const recognition = new SpeechRecognitionClass()\r\n-    recognition.lang = 'pt-BR'\r\n-    recognition.continuous = true\r\n-    recognition.interimResults = true\r\n+      const recognition = new SpeechRecognitionClass()\r\n+      recognition.lang = 'pt-BR'\r\n+      recognition.continuous = true\r\n+      recognition.interimResults = true\r\n \r\n-    recognition.onresult = (e: any) => {\r\n-      const texto = Array.from(e.results).map(r => r[0].transcript).join(' ')\r\n-      onTexto(texto) // üîÅ sempre substitui\r\n+      recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n+        const texto = Array.from(e.results)\r\n+          .map((r) => r[0].transcript)\r\n+          .join(' ')\r\n+        onTexto(texto)\r\n+      }\r\n+\r\n+      recognition.onerror = (e: any) => {\r\n+        setErro('Erro no reconhecimento de voz: ' + e.error)\r\n+      }\r\n+\r\n+      recognition.onend = () => {\r\n+        if (recognitionRef.current && gravandoRef.current) {\r\n+          recognitionRef.current.start()\r\n+        }\r\n+      }\r\n+\r\n+      recognitionRef.current = recognition\r\n     }\r\n \r\n-    recognitionRef.current = recognition\r\n-  }, [onTexto])\r\n+    return () => {\r\n+      recognitionRef.current?.stop?.()\r\n+    }\r\n+  }, [platform, onTexto])\r\n \r\n-  const start = () => {\r\n-    recognitionRef.current?.start()\r\n+  const start = async () => {\r\n+    setErro(null)\r\n+\r\n+    if (platform === 'android' || platform === 'ios') {\r\n+      const { speechRecognition } = await SpeechRecognition.requestPermissions()\r\n+      if (speechRecognition !== 'granted') {\r\n+        setErro('Permiss√£o negada para usar o microfone.')\r\n+        return\r\n+      }\r\n+\r\n+      await SpeechRecognition.start({\r\n+        language: 'pt-BR',\r\n+        partialResults: true,\r\n+        popup: false,\r\n+      })\r\n+\r\n+      // Remove listener anterior, se existir\r\n+      if (partialListenerRef.current) {\r\n+        await partialListenerRef.current.remove()\r\n+        partialListenerRef.current = null\r\n+      }\r\n+\r\n+      // Adiciona novo listener e salva refer√™ncia\r\n+      partialListenerRef.current = await SpeechRecognition.addListener(\r\n+        'partialResults',\r\n+        (data: { matches: string[] }) => {\r\n+          if (data.matches?.length) onTexto(data.matches[0])\r\n+        }\r\n+      )\r\n+    } else {\r\n+      try {\r\n+        const permissionStatus = await navigator.permissions?.query({\r\n+          name: 'microphone' as PermissionName,\r\n+        })\r\n+\r\n+        if (permissionStatus?.state === 'denied') {\r\n+          setErro('Permiss√£o de microfone negada pelo navegador. Verifique as configura√ß√µes do site.')\r\n+          return\r\n+        }\r\n+\r\n+        recognitionRef.current?.start()\r\n+      } catch (e) {\r\n+        setErro('Erro ao acessar o microfone. Verifique as permiss√µes do navegador.')\r\n+      }\r\n+    }\r\n+\r\n     setGravando(true)\r\n+    gravandoRef.current = true\r\n   }\r\n \r\n-  const stop = () => {\r\n-    recognitionRef.current?.stop()\r\n+  const stop = async () => {\r\n+    if (platform === 'android' || platform === 'ios') {\r\n+      await SpeechRecognition.stop()\r\n+\r\n+      if (partialListenerRef.current) {\r\n+        await partialListenerRef.current.remove()\r\n+        partialListenerRef.current = null\r\n+      }\r\n+\r\n+      await SpeechRecognition.removeAllListeners()\r\n+    } else {\r\n+      recognitionRef.current?.stop?.()\r\n+    }\r\n+\r\n     setGravando(false)\r\n+    gravandoRef.current = false\r\n   }\r\n \r\n   return {\r\n     gravando,\r\n+    erro,\r\n     start,\r\n-    stop\r\n+    stop,\r\n   }\r\n }\r\n"
                },
                {
                    "date": 1747773904619,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -15,18 +15,12 @@\n     readonly results: SpeechRecognitionResultList\r\n   }\r\n }\r\n \r\n-/**\r\n- * Op√ß√µes do hook useSpeechRecognition\r\n- */\r\n interface UseSpeechRecognitionOptions {\r\n   onTexto: (texto: string) => void\r\n }\r\n \r\n-/**\r\n- * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n- */\r\n export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n   const recognitionRef = useRef<any>(null)\r\n@@ -47,21 +41,21 @@\n       recognition.continuous = true\r\n       recognition.interimResults = true\r\n \r\n       recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-        const texto = Array.from(e.results)\r\n+        const textoAtual = Array.from(e.results)\r\n           .map((r) => r[0].transcript)\r\n           .join(' ')\r\n-        onTexto(texto)\r\n+        onTexto(textoAtual) // ‚úÖ substitui o texto em tempo real, sem concatenar duplicado\r\n       }\r\n \r\n       recognition.onerror = (e: any) => {\r\n         setErro('Erro no reconhecimento de voz: ' + e.error)\r\n       }\r\n \r\n       recognition.onend = () => {\r\n-        if (recognitionRef.current && gravandoRef.current) {\r\n-          recognitionRef.current.start()\r\n+        if (gravandoRef.current) {\r\n+          recognition.start() // mant√©m ativo enquanto gravando\r\n         }\r\n       }\r\n \r\n       recognitionRef.current = recognition\r\n@@ -87,19 +81,20 @@\n         partialResults: true,\r\n         popup: false,\r\n       })\r\n \r\n-      // Remove listener anterior, se existir\r\n+      // Remove listener anterior\r\n       if (partialListenerRef.current) {\r\n         await partialListenerRef.current.remove()\r\n         partialListenerRef.current = null\r\n       }\r\n \r\n-      // Adiciona novo listener e salva refer√™ncia\r\n       partialListenerRef.current = await SpeechRecognition.addListener(\r\n         'partialResults',\r\n         (data: { matches: string[] }) => {\r\n-          if (data.matches?.length) onTexto(data.matches[0])\r\n+          if (data.matches?.length) {\r\n+            onTexto(data.matches[0]) // ‚úÖ substitui (n√£o acumula)\r\n+          }\r\n         }\r\n       )\r\n     } else {\r\n       try {\r\n"
                },
                {
                    "date": 1747774798045,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,9 +63,9 @@\n \r\n     return () => {\r\n       recognitionRef.current?.stop?.()\r\n     }\r\n-  }, [platform, onTexto])\r\n+  }, [])\r\n \r\n   const start = async () => {\r\n     setErro(null)\r\n \r\n"
                },
                {
                    "date": 1747774835405,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,46 +27,44 @@\n   const gravandoRef = useRef(false)\r\n   const partialListenerRef = useRef<any>(null)\r\n   const platform = Capacitor.getPlatform()\r\n \r\n-  useEffect(() => {\r\n-    if (platform === 'web') {\r\n-      const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n-      if (!SpeechRecognitionClass) {\r\n-        setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n-        return\r\n-      }\r\n+useEffect(() => {\r\n+  if (platform !== 'web') return\r\n+  if (recognitionRef.current) return // evita recriar\r\n \r\n-      const recognition = new SpeechRecognitionClass()\r\n-      recognition.lang = 'pt-BR'\r\n-      recognition.continuous = true\r\n-      recognition.interimResults = true\r\n+  const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n+  if (!SpeechRecognitionClass) {\r\n+    setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n+    return\r\n+  }\r\n \r\n-      recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-        const textoAtual = Array.from(e.results)\r\n-          .map((r) => r[0].transcript)\r\n-          .join(' ')\r\n-        onTexto(textoAtual) // ‚úÖ substitui o texto em tempo real, sem concatenar duplicado\r\n-      }\r\n+  const recognition = new SpeechRecognitionClass()\r\n+  recognition.lang = 'pt-BR'\r\n+  recognition.continuous = true\r\n+  recognition.interimResults = true\r\n \r\n-      recognition.onerror = (e: any) => {\r\n-        setErro('Erro no reconhecimento de voz: ' + e.error)\r\n-      }\r\n+  recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n+    const textoAtual = Array.from(e.results)\r\n+      .map((r) => r[0].transcript)\r\n+      .join(' ')\r\n+    onTexto(textoAtual)\r\n+  }\r\n \r\n-      recognition.onend = () => {\r\n-        if (gravandoRef.current) {\r\n-          recognition.start() // mant√©m ativo enquanto gravando\r\n-        }\r\n-      }\r\n+  recognition.onerror = (e: any) => {\r\n+    setErro('Erro no reconhecimento de voz: ' + e.error)\r\n+  }\r\n \r\n-      recognitionRef.current = recognition\r\n+  recognition.onend = () => {\r\n+    if (gravandoRef.current) {\r\n+      recognition.start()\r\n     }\r\n+  }\r\n \r\n-    return () => {\r\n-      recognitionRef.current?.stop?.()\r\n-    }\r\n-  }, [])\r\n+  recognitionRef.current = recognition\r\n+}, []) // üîí Executa s√≥ uma vez\r\n \r\n+\r\n   const start = async () => {\r\n     setErro(null)\r\n \r\n     if (platform === 'android' || platform === 'ios') {\r\n"
                },
                {
                    "date": 1747775092012,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -43,8 +43,9 @@\n   recognition.continuous = true\r\n   recognition.interimResults = true\r\n \r\n   recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n+    console.info('som: ', e)\r\n     const textoAtual = Array.from(e.results)\r\n       .map((r) => r[0].transcript)\r\n       .join(' ')\r\n     onTexto(textoAtual)\r\n"
                },
                {
                    "date": 1747775517851,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -43,15 +43,15 @@\n   recognition.continuous = true\r\n   recognition.interimResults = true\r\n \r\n   recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-    console.info('som: ', e)\r\n-    const textoAtual = Array.from(e.results)\r\n-      .map((r) => r[0].transcript)\r\n-      .join(' ')\r\n-    onTexto(textoAtual)\r\n+    const { resultIndex, results } = e\r\n+\r\n+    const textoNovo = results[resultIndex][0].transcript\r\n+    onTexto(textoNovo)\r\n   }\r\n \r\n+\r\n   recognition.onerror = (e: any) => {\r\n     setErro('Erro no reconhecimento de voz: ' + e.error)\r\n   }\r\n \r\n"
                },
                {
                    "date": 1747775819730,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -15,57 +15,64 @@\n     readonly results: SpeechRecognitionResultList\r\n   }\r\n }\r\n \r\n+/**\r\n+ * Op√ß√µes do hook useSpeechRecognition\r\n+ */\r\n interface UseSpeechRecognitionOptions {\r\n   onTexto: (texto: string) => void\r\n }\r\n \r\n+/**\r\n+ * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n+ */\r\n export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n   const recognitionRef = useRef<any>(null)\r\n   const gravandoRef = useRef(false)\r\n   const partialListenerRef = useRef<any>(null)\r\n   const platform = Capacitor.getPlatform()\r\n \r\n-useEffect(() => {\r\n-  if (platform !== 'web') return\r\n-  if (recognitionRef.current) return // evita recriar\r\n+  useEffect(() => {\r\n+    if (platform === 'web') {\r\n+      const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n+      if (!SpeechRecognitionClass) {\r\n+        setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n+        return\r\n+      }\r\n \r\n-  const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n-  if (!SpeechRecognitionClass) {\r\n-    setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n-    return\r\n-  }\r\n+      const recognition = new SpeechRecognitionClass()\r\n+      recognition.lang = 'pt-BR'\r\n+      recognition.continuous = true\r\n+      recognition.interimResults = true\r\n \r\n-  const recognition = new SpeechRecognitionClass()\r\n-  recognition.lang = 'pt-BR'\r\n-  recognition.continuous = true\r\n-  recognition.interimResults = true\r\n+      recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n+        const texto = Array.from(e.results)\r\n+          .map((r) => r[0].transcript)\r\n+          .join(' ')\r\n+        onTexto(texto)\r\n+      }\r\n \r\n-  recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-    const { resultIndex, results } = e\r\n+      recognition.onerror = (e: any) => {\r\n+        setErro('Erro no reconhecimento de voz: ' + e.error)\r\n+      }\r\n \r\n-    const textoNovo = results[resultIndex][0].transcript\r\n-    onTexto(textoNovo)\r\n-  }\r\n+      recognition.onend = () => {\r\n+        if (recognitionRef.current && gravandoRef.current) {\r\n+          recognitionRef.current.start()\r\n+        }\r\n+      }\r\n \r\n+      recognitionRef.current = recognition\r\n+    }\r\n \r\n-  recognition.onerror = (e: any) => {\r\n-    setErro('Erro no reconhecimento de voz: ' + e.error)\r\n-  }\r\n-\r\n-  recognition.onend = () => {\r\n-    if (gravandoRef.current) {\r\n-      recognition.start()\r\n+    return () => {\r\n+      recognitionRef.current?.stop?.()\r\n     }\r\n-  }\r\n+  }, [platform, onTexto])\r\n \r\n-  recognitionRef.current = recognition\r\n-}, []) // üîí Executa s√≥ uma vez\r\n-\r\n-\r\n   const start = async () => {\r\n     setErro(null)\r\n \r\n     if (platform === 'android' || platform === 'ios') {\r\n@@ -80,20 +87,19 @@\n         partialResults: true,\r\n         popup: false,\r\n       })\r\n \r\n-      // Remove listener anterior\r\n+      // Remove listener anterior, se existir\r\n       if (partialListenerRef.current) {\r\n         await partialListenerRef.current.remove()\r\n         partialListenerRef.current = null\r\n       }\r\n \r\n+      // Adiciona novo listener e salva refer√™ncia\r\n       partialListenerRef.current = await SpeechRecognition.addListener(\r\n         'partialResults',\r\n         (data: { matches: string[] }) => {\r\n-          if (data.matches?.length) {\r\n-            onTexto(data.matches[0]) // ‚úÖ substitui (n√£o acumula)\r\n-          }\r\n+          if (data.matches?.length) onTexto(data.matches[0])\r\n         }\r\n       )\r\n     } else {\r\n       try {\r\n"
                },
                {
                    "date": 1747776236392,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,78 +1,46 @@\n-import { useEffect, useRef, useState } from 'react'\r\n-import { Capacitor } from '@capacitor/core'\r\n-import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n-\r\n-/**\r\n- * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n- */\r\n-declare global {\r\n-  interface Window {\r\n-    webkitSpeechRecognition: any\r\n-    SpeechRecognition: any\r\n-  }\r\n-\r\n-  interface SpeechRecognitionEvent extends Event {\r\n-    readonly results: SpeechRecognitionResultList\r\n-  }\r\n-}\r\n-\r\n-/**\r\n- * Op√ß√µes do hook useSpeechRecognition\r\n- */\r\n-interface UseSpeechRecognitionOptions {\r\n-  onTexto: (texto: string) => void\r\n-}\r\n-\r\n-/**\r\n- * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n- */\r\n-export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n+export function useSpeechRecognition() {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n+  const [texto, setTexto] = useState('')\r\n   const recognitionRef = useRef<any>(null)\r\n   const gravandoRef = useRef(false)\r\n   const partialListenerRef = useRef<any>(null)\r\n   const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n-    if (platform === 'web') {\r\n-      const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n-      if (!SpeechRecognitionClass) {\r\n-        setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n-        return\r\n-      }\r\n+    if (platform !== 'web') return\r\n+    if (recognitionRef.current) return\r\n \r\n-      const recognition = new SpeechRecognitionClass()\r\n-      recognition.lang = 'pt-BR'\r\n-      recognition.continuous = true\r\n-      recognition.interimResults = true\r\n+    const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n+    if (!SpeechRecognitionClass) {\r\n+      setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n+      return\r\n+    }\r\n \r\n-      recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-        const texto = Array.from(e.results)\r\n-          .map((r) => r[0].transcript)\r\n-          .join(' ')\r\n-        onTexto(texto)\r\n-      }\r\n+    const recognition = new SpeechRecognitionClass()\r\n+    recognition.lang = 'pt-BR'\r\n+    recognition.continuous = true\r\n+    recognition.interimResults = true\r\n \r\n-      recognition.onerror = (e: any) => {\r\n-        setErro('Erro no reconhecimento de voz: ' + e.error)\r\n-      }\r\n+    recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n+      const novoTexto = e.results[e.resultIndex][0].transcript\r\n+      setTexto((prev) => `${prev} ${novoTexto}`.trim())\r\n+    }\r\n \r\n-      recognition.onend = () => {\r\n-        if (recognitionRef.current && gravandoRef.current) {\r\n-          recognitionRef.current.start()\r\n-        }\r\n-      }\r\n-\r\n-      recognitionRef.current = recognition\r\n+    recognition.onerror = (e: any) => {\r\n+      setErro('Erro no reconhecimento de voz: ' + e.error)\r\n     }\r\n \r\n-    return () => {\r\n-      recognitionRef.current?.stop?.()\r\n+    recognition.onend = () => {\r\n+      if (gravandoRef.current) {\r\n+        setTimeout(() => recognition.start(), 100)\r\n+      }\r\n     }\r\n-  }, [platform, onTexto])\r\n \r\n+    recognitionRef.current = recognition\r\n+  }, [])\r\n+\r\n   const start = async () => {\r\n     setErro(null)\r\n \r\n     if (platform === 'android' || platform === 'ios') {\r\n@@ -87,36 +55,31 @@\n         partialResults: true,\r\n         popup: false,\r\n       })\r\n \r\n-      // Remove listener anterior, se existir\r\n       if (partialListenerRef.current) {\r\n         await partialListenerRef.current.remove()\r\n-        partialListenerRef.current = null\r\n       }\r\n \r\n-      // Adiciona novo listener e salva refer√™ncia\r\n       partialListenerRef.current = await SpeechRecognition.addListener(\r\n         'partialResults',\r\n         (data: { matches: string[] }) => {\r\n-          if (data.matches?.length) onTexto(data.matches[0])\r\n+          if (data.matches?.length) {\r\n+            setTexto((prev) => `${prev} ${data.matches[0]}`.trim())\r\n+          }\r\n         }\r\n       )\r\n     } else {\r\n-      try {\r\n-        const permissionStatus = await navigator.permissions?.query({\r\n-          name: 'microphone' as PermissionName,\r\n-        })\r\n+      const permissionStatus = await navigator.permissions?.query({\r\n+        name: 'microphone' as PermissionName,\r\n+      })\r\n \r\n-        if (permissionStatus?.state === 'denied') {\r\n-          setErro('Permiss√£o de microfone negada pelo navegador. Verifique as configura√ß√µes do site.')\r\n-          return\r\n-        }\r\n+      if (permissionStatus?.state === 'denied') {\r\n+        setErro('Permiss√£o de microfone negada pelo navegador.')\r\n+        return\r\n+      }\r\n \r\n-        recognitionRef.current?.start()\r\n-      } catch (e) {\r\n-        setErro('Erro ao acessar o microfone. Verifique as permiss√µes do navegador.')\r\n-      }\r\n+      recognitionRef.current?.start()\r\n     }\r\n \r\n     setGravando(true)\r\n     gravandoRef.current = true\r\n@@ -140,10 +103,12 @@\n     gravandoRef.current = false\r\n   }\r\n \r\n   return {\r\n+    texto,\r\n+    erro,\r\n     gravando,\r\n-    erro,\r\n     start,\r\n     stop,\r\n+    setTexto // exp√µe se o dev quiser limpar manualmente\r\n   }\r\n }\r\n"
                },
                {
                    "date": 1747776345296,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,46 +1,78 @@\n-export function useSpeechRecognition() {\r\n+import { useEffect, useRef, useState } from 'react'\r\n+import { Capacitor } from '@capacitor/core'\r\n+import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n+\r\n+/**\r\n+ * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n+ */\r\n+declare global {\r\n+  interface Window {\r\n+    webkitSpeechRecognition: any\r\n+    SpeechRecognition: any\r\n+  }\r\n+\r\n+  interface SpeechRecognitionEvent extends Event {\r\n+    readonly results: SpeechRecognitionResultList\r\n+  }\r\n+}\r\n+\r\n+/**\r\n+ * Op√ß√µes do hook useSpeechRecognition\r\n+ */\r\n+interface UseSpeechRecognitionOptions {\r\n+  onTexto: (texto: string) => void\r\n+}\r\n+\r\n+/**\r\n+ * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n+ */\r\n+export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n-  const [texto, setTexto] = useState('')\r\n   const recognitionRef = useRef<any>(null)\r\n   const gravandoRef = useRef(false)\r\n   const partialListenerRef = useRef<any>(null)\r\n   const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n-    if (platform !== 'web') return\r\n-    if (recognitionRef.current) return\r\n+    if (platform === 'web') {\r\n+      const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n+      if (!SpeechRecognitionClass) {\r\n+        setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n+        return\r\n+      }\r\n \r\n-    const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n-    if (!SpeechRecognitionClass) {\r\n-      setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n-      return\r\n-    }\r\n+      const recognition = new SpeechRecognitionClass()\r\n+      recognition.lang = 'pt-BR'\r\n+      recognition.continuous = true\r\n+      recognition.interimResults = true\r\n \r\n-    const recognition = new SpeechRecognitionClass()\r\n-    recognition.lang = 'pt-BR'\r\n-    recognition.continuous = true\r\n-    recognition.interimResults = true\r\n+      recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n+        const texto = Array.from(e.results)\r\n+          .map((r) => r[0].transcript)\r\n+          .join(' ')\r\n+        onTexto(texto)\r\n+      }\r\n \r\n-    recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-      const novoTexto = e.results[e.resultIndex][0].transcript\r\n-      setTexto((prev) => `${prev} ${novoTexto}`.trim())\r\n-    }\r\n+      recognition.onerror = (e: any) => {\r\n+        setErro('Erro no reconhecimento de voz: ' + e.error)\r\n+      }\r\n \r\n-    recognition.onerror = (e: any) => {\r\n-      setErro('Erro no reconhecimento de voz: ' + e.error)\r\n+      recognition.onend = () => {\r\n+        if (recognitionRef.current && gravandoRef.current) {\r\n+          recognitionRef.current.start()\r\n+        }\r\n+      }\r\n+\r\n+      recognitionRef.current = recognition\r\n     }\r\n \r\n-    recognition.onend = () => {\r\n-      if (gravandoRef.current) {\r\n-        setTimeout(() => recognition.start(), 100)\r\n-      }\r\n+    return () => {\r\n+      recognitionRef.current?.stop?.()\r\n     }\r\n+  }, [platform, onTexto])\r\n \r\n-    recognitionRef.current = recognition\r\n-  }, [])\r\n-\r\n   const start = async () => {\r\n     setErro(null)\r\n \r\n     if (platform === 'android' || platform === 'ios') {\r\n@@ -55,31 +87,36 @@\n         partialResults: true,\r\n         popup: false,\r\n       })\r\n \r\n+      // Remove listener anterior, se existir\r\n       if (partialListenerRef.current) {\r\n         await partialListenerRef.current.remove()\r\n+        partialListenerRef.current = null\r\n       }\r\n \r\n+      // Adiciona novo listener e salva refer√™ncia\r\n       partialListenerRef.current = await SpeechRecognition.addListener(\r\n         'partialResults',\r\n         (data: { matches: string[] }) => {\r\n-          if (data.matches?.length) {\r\n-            setTexto((prev) => `${prev} ${data.matches[0]}`.trim())\r\n-          }\r\n+          if (data.matches?.length) onTexto(data.matches[0])\r\n         }\r\n       )\r\n     } else {\r\n-      const permissionStatus = await navigator.permissions?.query({\r\n-        name: 'microphone' as PermissionName,\r\n-      })\r\n+      try {\r\n+        const permissionStatus = await navigator.permissions?.query({\r\n+          name: 'microphone' as PermissionName,\r\n+        })\r\n \r\n-      if (permissionStatus?.state === 'denied') {\r\n-        setErro('Permiss√£o de microfone negada pelo navegador.')\r\n-        return\r\n+        if (permissionStatus?.state === 'denied') {\r\n+          setErro('Permiss√£o de microfone negada pelo navegador. Verifique as configura√ß√µes do site.')\r\n+          return\r\n+        }\r\n+\r\n+        recognitionRef.current?.start()\r\n+      } catch (e) {\r\n+        setErro('Erro ao acessar o microfone. Verifique as permiss√µes do navegador.')\r\n       }\r\n-\r\n-      recognitionRef.current?.start()\r\n     }\r\n \r\n     setGravando(true)\r\n     gravandoRef.current = true\r\n@@ -103,12 +140,10 @@\n     gravandoRef.current = false\r\n   }\r\n \r\n   return {\r\n-    texto,\r\n+    gravando,\r\n     erro,\r\n-    gravando,\r\n     start,\r\n     stop,\r\n-    setTexto // exp√µe se o dev quiser limpar manualmente\r\n   }\r\n }\r\n"
                },
                {
                    "date": 1747776357759,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,78 +1,46 @@\n-import { useEffect, useRef, useState } from 'react'\r\n-import { Capacitor } from '@capacitor/core'\r\n-import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n-\r\n-/**\r\n- * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n- */\r\n-declare global {\r\n-  interface Window {\r\n-    webkitSpeechRecognition: any\r\n-    SpeechRecognition: any\r\n-  }\r\n-\r\n-  interface SpeechRecognitionEvent extends Event {\r\n-    readonly results: SpeechRecognitionResultList\r\n-  }\r\n-}\r\n-\r\n-/**\r\n- * Op√ß√µes do hook useSpeechRecognition\r\n- */\r\n-interface UseSpeechRecognitionOptions {\r\n-  onTexto: (texto: string) => void\r\n-}\r\n-\r\n-/**\r\n- * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n- */\r\n-export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n+export function useSpeechRecognition() {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n+  const [texto, setTexto] = useState('')\r\n   const recognitionRef = useRef<any>(null)\r\n   const gravandoRef = useRef(false)\r\n   const partialListenerRef = useRef<any>(null)\r\n   const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n-    if (platform === 'web') {\r\n-      const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n-      if (!SpeechRecognitionClass) {\r\n-        setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n-        return\r\n-      }\r\n+    if (platform !== 'web') return\r\n+    if (recognitionRef.current) return\r\n \r\n-      const recognition = new SpeechRecognitionClass()\r\n-      recognition.lang = 'pt-BR'\r\n-      recognition.continuous = true\r\n-      recognition.interimResults = true\r\n+    const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n+    if (!SpeechRecognitionClass) {\r\n+      setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n+      return\r\n+    }\r\n \r\n-      recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-        const texto = Array.from(e.results)\r\n-          .map((r) => r[0].transcript)\r\n-          .join(' ')\r\n-        onTexto(texto)\r\n-      }\r\n+    const recognition = new SpeechRecognitionClass()\r\n+    recognition.lang = 'pt-BR'\r\n+    recognition.continuous = true\r\n+    recognition.interimResults = true\r\n \r\n-      recognition.onerror = (e: any) => {\r\n-        setErro('Erro no reconhecimento de voz: ' + e.error)\r\n-      }\r\n+    recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n+      const novoTexto = e.results[e.resultIndex][0].transcript\r\n+      setTexto((prev) => `${prev} ${novoTexto}`.trim())\r\n+    }\r\n \r\n-      recognition.onend = () => {\r\n-        if (recognitionRef.current && gravandoRef.current) {\r\n-          recognitionRef.current.start()\r\n-        }\r\n-      }\r\n-\r\n-      recognitionRef.current = recognition\r\n+    recognition.onerror = (e: any) => {\r\n+      setErro('Erro no reconhecimento de voz: ' + e.error)\r\n     }\r\n \r\n-    return () => {\r\n-      recognitionRef.current?.stop?.()\r\n+    recognition.onend = () => {\r\n+      if (gravandoRef.current) {\r\n+        setTimeout(() => recognition.start(), 100)\r\n+      }\r\n     }\r\n-  }, [platform, onTexto])\r\n \r\n+    recognitionRef.current = recognition\r\n+  }, [])\r\n+\r\n   const start = async () => {\r\n     setErro(null)\r\n \r\n     if (platform === 'android' || platform === 'ios') {\r\n@@ -87,36 +55,31 @@\n         partialResults: true,\r\n         popup: false,\r\n       })\r\n \r\n-      // Remove listener anterior, se existir\r\n       if (partialListenerRef.current) {\r\n         await partialListenerRef.current.remove()\r\n-        partialListenerRef.current = null\r\n       }\r\n \r\n-      // Adiciona novo listener e salva refer√™ncia\r\n       partialListenerRef.current = await SpeechRecognition.addListener(\r\n         'partialResults',\r\n         (data: { matches: string[] }) => {\r\n-          if (data.matches?.length) onTexto(data.matches[0])\r\n+          if (data.matches?.length) {\r\n+            setTexto((prev) => `${prev} ${data.matches[0]}`.trim())\r\n+          }\r\n         }\r\n       )\r\n     } else {\r\n-      try {\r\n-        const permissionStatus = await navigator.permissions?.query({\r\n-          name: 'microphone' as PermissionName,\r\n-        })\r\n+      const permissionStatus = await navigator.permissions?.query({\r\n+        name: 'microphone' as PermissionName,\r\n+      })\r\n \r\n-        if (permissionStatus?.state === 'denied') {\r\n-          setErro('Permiss√£o de microfone negada pelo navegador. Verifique as configura√ß√µes do site.')\r\n-          return\r\n-        }\r\n+      if (permissionStatus?.state === 'denied') {\r\n+        setErro('Permiss√£o de microfone negada pelo navegador.')\r\n+        return\r\n+      }\r\n \r\n-        recognitionRef.current?.start()\r\n-      } catch (e) {\r\n-        setErro('Erro ao acessar o microfone. Verifique as permiss√µes do navegador.')\r\n-      }\r\n+      recognitionRef.current?.start()\r\n     }\r\n \r\n     setGravando(true)\r\n     gravandoRef.current = true\r\n@@ -140,10 +103,12 @@\n     gravandoRef.current = false\r\n   }\r\n \r\n   return {\r\n+    texto,\r\n+    erro,\r\n     gravando,\r\n-    erro,\r\n     start,\r\n     stop,\r\n+    setTexto // exp√µe se o dev quiser limpar manualmente\r\n   }\r\n }\r\n"
                },
                {
                    "date": 1747776381330,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,4 +1,32 @@\n+import { useEffect, useRef, useState } from 'react'\r\n+import { Capacitor } from '@capacitor/core'\r\n+import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n+\r\n+/**\r\n+ * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n+ */\r\n+declare global {\r\n+  interface Window {\r\n+    webkitSpeechRecognition: any\r\n+    SpeechRecognition: any\r\n+  }\r\n+\r\n+  interface SpeechRecognitionEvent extends Event {\r\n+    readonly results: SpeechRecognitionResultList\r\n+  }\r\n+}\r\n+\r\n+/**\r\n+ * Op√ß√µes do hook useSpeechRecognition\r\n+ */\r\n+interface UseSpeechRecognitionOptions {\r\n+  onTexto: (texto: string) => void\r\n+}\r\n+\r\n+/**\r\n+ * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n+ */\r\n export function useSpeechRecognition() {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n   const [texto, setTexto] = useState('')\r\n"
                },
                {
                    "date": 1747776427438,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,50 +25,54 @@\n \r\n /**\r\n  * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n  */\r\n-export function useSpeechRecognition() {\r\n+export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n-  const [texto, setTexto] = useState('')\r\n   const recognitionRef = useRef<any>(null)\r\n   const gravandoRef = useRef(false)\r\n   const partialListenerRef = useRef<any>(null)\r\n   const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n-    if (platform !== 'web') return\r\n-    if (recognitionRef.current) return\r\n+    if (platform === 'web') {\r\n+      const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n+      if (!SpeechRecognitionClass) {\r\n+        setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n+        return\r\n+      }\r\n \r\n-    const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n-    if (!SpeechRecognitionClass) {\r\n-      setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n-      return\r\n-    }\r\n+      const recognition = new SpeechRecognitionClass()\r\n+      recognition.lang = 'pt-BR'\r\n+      recognition.continuous = true\r\n+      recognition.interimResults = true\r\n \r\n-    const recognition = new SpeechRecognitionClass()\r\n-    recognition.lang = 'pt-BR'\r\n-    recognition.continuous = true\r\n-    recognition.interimResults = true\r\n+      recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n+        const texto = Array.from(e.results)\r\n+          .map((r) => r[0].transcript)\r\n+          .join(' ')\r\n+        onTexto(texto)\r\n+      }\r\n \r\n-    recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-      const novoTexto = e.results[e.resultIndex][0].transcript\r\n-      setTexto((prev) => `${prev} ${novoTexto}`.trim())\r\n-    }\r\n+      recognition.onerror = (e: any) => {\r\n+        setErro('Erro no reconhecimento de voz: ' + e.error)\r\n+      }\r\n \r\n-    recognition.onerror = (e: any) => {\r\n-      setErro('Erro no reconhecimento de voz: ' + e.error)\r\n+      recognition.onend = () => {\r\n+        if (recognitionRef.current && gravandoRef.current) {\r\n+          recognitionRef.current.start()\r\n+        }\r\n+      }\r\n+\r\n+      recognitionRef.current = recognition\r\n     }\r\n \r\n-    recognition.onend = () => {\r\n-      if (gravandoRef.current) {\r\n-        setTimeout(() => recognition.start(), 100)\r\n-      }\r\n+    return () => {\r\n+      recognitionRef.current?.stop?.()\r\n     }\r\n+  }, [platform, onTexto])\r\n \r\n-    recognitionRef.current = recognition\r\n-  }, [])\r\n-\r\n   const start = async () => {\r\n     setErro(null)\r\n \r\n     if (platform === 'android' || platform === 'ios') {\r\n@@ -83,31 +87,36 @@\n         partialResults: true,\r\n         popup: false,\r\n       })\r\n \r\n+      // Remove listener anterior, se existir\r\n       if (partialListenerRef.current) {\r\n         await partialListenerRef.current.remove()\r\n+        partialListenerRef.current = null\r\n       }\r\n \r\n+      // Adiciona novo listener e salva refer√™ncia\r\n       partialListenerRef.current = await SpeechRecognition.addListener(\r\n         'partialResults',\r\n         (data: { matches: string[] }) => {\r\n-          if (data.matches?.length) {\r\n-            setTexto((prev) => `${prev} ${data.matches[0]}`.trim())\r\n-          }\r\n+          if (data.matches?.length) onTexto(data.matches[0])\r\n         }\r\n       )\r\n     } else {\r\n-      const permissionStatus = await navigator.permissions?.query({\r\n-        name: 'microphone' as PermissionName,\r\n-      })\r\n+      try {\r\n+        const permissionStatus = await navigator.permissions?.query({\r\n+          name: 'microphone' as PermissionName,\r\n+        })\r\n \r\n-      if (permissionStatus?.state === 'denied') {\r\n-        setErro('Permiss√£o de microfone negada pelo navegador.')\r\n-        return\r\n+        if (permissionStatus?.state === 'denied') {\r\n+          setErro('Permiss√£o de microfone negada pelo navegador. Verifique as configura√ß√µes do site.')\r\n+          return\r\n+        }\r\n+\r\n+        recognitionRef.current?.start()\r\n+      } catch (e) {\r\n+        setErro('Erro ao acessar o microfone. Verifique as permiss√µes do navegador.')\r\n       }\r\n-\r\n-      recognitionRef.current?.start()\r\n     }\r\n \r\n     setGravando(true)\r\n     gravandoRef.current = true\r\n@@ -131,12 +140,10 @@\n     gravandoRef.current = false\r\n   }\r\n \r\n   return {\r\n-    texto,\r\n+    gravando,\r\n     erro,\r\n-    gravando,\r\n     start,\r\n     stop,\r\n-    setTexto // exp√µe se o dev quiser limpar manualmente\r\n   }\r\n }\r\n"
                },
                {
                    "date": 1747776807763,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -69,9 +69,9 @@\n \r\n     return () => {\r\n       recognitionRef.current?.stop?.()\r\n     }\r\n-  }, [platform, onTexto])\r\n+  }, [])\r\n \r\n   const start = async () => {\r\n     setErro(null)\r\n \r\n"
                },
                {
                    "date": 1747776832514,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -28,8 +28,10 @@\n  */\r\n export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n+  const [texto, setTexto] = useState('')\r\n+\r\n   const recognitionRef = useRef<any>(null)\r\n   const gravandoRef = useRef(false)\r\n   const partialListenerRef = useRef<any>(null)\r\n   const platform = Capacitor.getPlatform()\r\n"
                },
                {
                    "date": 1747776858301,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -36,8 +36,11 @@\n   const partialListenerRef = useRef<any>(null)\r\n   const platform = Capacitor.getPlatform()\r\n \r\n   useEffect(() => {\r\n+    if (platform !== 'web') return\r\n+    if (recognitionRef.current) return\r\n+    \r\n     if (platform === 'web') {\r\n       const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n       if (!SpeechRecognitionClass) {\r\n         setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n"
                },
                {
                    "date": 1747776877140,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,146 @@\n+import { useEffect, useRef, useState } from 'react'\r\n+import { Capacitor } from '@capacitor/core'\r\n+import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n+\r\n+/**\r\n+ * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n+ */\r\n+declare global {\r\n+  interface Window {\r\n+    webkitSpeechRecognition: any\r\n+    SpeechRecognition: any\r\n+  }\r\n+\r\n+  interface SpeechRecognitionEvent extends Event {\r\n+    readonly results: SpeechRecognitionResultList\r\n+  }\r\n+}\r\n+\r\n+/**\r\n+ * Op√ß√µes do hook useSpeechRecognition\r\n+ */\r\n+interface UseSpeechRecognitionOptions {\r\n+  onTexto: (texto: string) => void\r\n+}\r\n+\r\n+/**\r\n+ * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n+ */\r\n+export function useSpeechRecognition() {\r\n+  const [gravando, setGravando] = useState(false)\r\n+  const [erro, setErro] = useState<string | null>(null)\r\n+  const [texto, setTexto] = useState('')\r\n+\r\n+  const recognitionRef = useRef<any>(null)\r\n+  const gravandoRef = useRef(false)\r\n+  const partialListenerRef = useRef<any>(null)\r\n+  const platform = Capacitor.getPlatform()\r\n+\r\n+  useEffect(() => {\r\n+    if (platform !== 'web') return\r\n+    if (recognitionRef.current) return\r\n+\r\n+    const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n+    if (!SpeechRecognitionClass) {\r\n+      setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n+      return\r\n+    }\r\n+\r\n+    const recognition = new SpeechRecognitionClass()\r\n+    recognition.lang = 'pt-BR'\r\n+    recognition.continuous = true\r\n+    recognition.interimResults = true\r\n+\r\n+    recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n+      const novo = e.results[e.resultIndex][0].transcript\r\n+      setTexto((prev) => `${prev} ${novo}`.trim())\r\n+    }\r\n+\r\n+    recognition.onerror = (e: any) => {\r\n+      setErro('Erro no reconhecimento de voz: ' + e.error)\r\n+    }\r\n+\r\n+    recognition.onend = () => {\r\n+      if (gravandoRef.current) {\r\n+        setTimeout(() => recognition.start(), 100)\r\n+      }\r\n+    }\r\n+\r\n+    recognitionRef.current = recognition\r\n+  }, [])\r\n+\r\n+  const start = async () => {\r\n+    setErro(null)\r\n+    setTexto('')\r\n+\r\n+    if (platform === 'android' || platform === 'ios') {\r\n+      const { speechRecognition } = await SpeechRecognition.requestPermissions()\r\n+      if (speechRecognition !== 'granted') {\r\n+        setErro('Permiss√£o negada para usar o microfone.')\r\n+        return\r\n+      }\r\n+\r\n+      await SpeechRecognition.start({\r\n+        language: 'pt-BR',\r\n+        partialResults: true,\r\n+        popup: false,\r\n+      })\r\n+\r\n+      if (partialListenerRef.current) {\r\n+        await partialListenerRef.current.remove()\r\n+        partialListenerRef.current = null\r\n+      }\r\n+\r\n+      partialListenerRef.current = await SpeechRecognition.addListener(\r\n+        'partialResults',\r\n+        (data: { matches: string[] }) => {\r\n+          if (data.matches?.length) {\r\n+            setTexto((prev) => `${prev} ${data.matches[0]}`.trim())\r\n+          }\r\n+        }\r\n+      )\r\n+    } else {\r\n+      try {\r\n+        const permissionStatus = await navigator.permissions?.query({\r\n+          name: 'microphone' as PermissionName,\r\n+        })\r\n+        if (permissionStatus?.state === 'denied') {\r\n+          setErro('Permiss√£o de microfone negada pelo navegador.')\r\n+          return\r\n+        }\r\n+        recognitionRef.current?.start()\r\n+      } catch (e) {\r\n+        setErro('Erro ao acessar o microfone.')\r\n+      }\r\n+    }\r\n+\r\n+    setGravando(true)\r\n+    gravandoRef.current = true\r\n+  }\r\n+\r\n+  const stop = async () => {\r\n+    if (platform === 'android' || platform === 'ios') {\r\n+      await SpeechRecognition.stop()\r\n+      if (partialListenerRef.current) {\r\n+        await partialListenerRef.current.remove()\r\n+        partialListenerRef.current = null\r\n+      }\r\n+      await SpeechRecognition.removeAllListeners()\r\n+    } else {\r\n+      recognitionRef.current?.stop?.()\r\n+    }\r\n+\r\n+    setGravando(false)\r\n+    gravandoRef.current = false\r\n+  }\r\n+\r\n+  return {\r\n+    texto,\r\n+    erro,\r\n+    gravando,\r\n+    start,\r\n+    stop,\r\n+    setTexto, // opcional, se quiser permitir reset manual\r\n+  }\r\n+}\r\n+\r\n"
                },
                {
                    "date": 1747776922188,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,8 +12,9 @@\n   }\r\n \r\n   interface SpeechRecognitionEvent extends Event {\r\n     readonly results: SpeechRecognitionResultList\r\n+    readonly resultIndex: number // üëà adicione isso\r\n   }\r\n }\r\n \r\n /**\r\n@@ -143,158 +144,4 @@\n     setTexto, // opcional, se quiser permitir reset manual\r\n   }\r\n }\r\n \r\n-import { useEffect, useRef, useState } from 'react'\r\n-import { Capacitor } from '@capacitor/core'\r\n-import { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n-\r\n-/**\r\n- * Declara√ß√µes globais necess√°rias para a API Web Speech\r\n- */\r\n-declare global {\r\n-  interface Window {\r\n-    webkitSpeechRecognition: any\r\n-    SpeechRecognition: any\r\n-  }\r\n-\r\n-  interface SpeechRecognitionEvent extends Event {\r\n-    readonly results: SpeechRecognitionResultList\r\n-  }\r\n-}\r\n-\r\n-/**\r\n- * Op√ß√µes do hook useSpeechRecognition\r\n- */\r\n-interface UseSpeechRecognitionOptions {\r\n-  onTexto: (texto: string) => void\r\n-}\r\n-\r\n-/**\r\n- * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n- */\r\n-export function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n-  const [gravando, setGravando] = useState(false)\r\n-  const [erro, setErro] = useState<string | null>(null)\r\n-  const [texto, setTexto] = useState('')\r\n-\r\n-  const recognitionRef = useRef<any>(null)\r\n-  const gravandoRef = useRef(false)\r\n-  const partialListenerRef = useRef<any>(null)\r\n-  const platform = Capacitor.getPlatform()\r\n-\r\n-  useEffect(() => {\r\n-    if (platform !== 'web') return\r\n-    if (recognitionRef.current) return\r\n-    \r\n-    if (platform === 'web') {\r\n-      const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n-      if (!SpeechRecognitionClass) {\r\n-        setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n-        return\r\n-      }\r\n-\r\n-      const recognition = new SpeechRecognitionClass()\r\n-      recognition.lang = 'pt-BR'\r\n-      recognition.continuous = true\r\n-      recognition.interimResults = true\r\n-\r\n-      recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-        const texto = Array.from(e.results)\r\n-          .map((r) => r[0].transcript)\r\n-          .join(' ')\r\n-        onTexto(texto)\r\n-      }\r\n-\r\n-      recognition.onerror = (e: any) => {\r\n-        setErro('Erro no reconhecimento de voz: ' + e.error)\r\n-      }\r\n-\r\n-      recognition.onend = () => {\r\n-        if (recognitionRef.current && gravandoRef.current) {\r\n-          recognitionRef.current.start()\r\n-        }\r\n-      }\r\n-\r\n-      recognitionRef.current = recognition\r\n-    }\r\n-\r\n-    return () => {\r\n-      recognitionRef.current?.stop?.()\r\n-    }\r\n-  }, [])\r\n-\r\n-  const start = async () => {\r\n-    setErro(null)\r\n-\r\n-    if (platform === 'android' || platform === 'ios') {\r\n-      const { speechRecognition } = await SpeechRecognition.requestPermissions()\r\n-      if (speechRecognition !== 'granted') {\r\n-        setErro('Permiss√£o negada para usar o microfone.')\r\n-        return\r\n-      }\r\n-\r\n-      await SpeechRecognition.start({\r\n-        language: 'pt-BR',\r\n-        partialResults: true,\r\n-        popup: false,\r\n-      })\r\n-\r\n-      // Remove listener anterior, se existir\r\n-      if (partialListenerRef.current) {\r\n-        await partialListenerRef.current.remove()\r\n-        partialListenerRef.current = null\r\n-      }\r\n-\r\n-      // Adiciona novo listener e salva refer√™ncia\r\n-      partialListenerRef.current = await SpeechRecognition.addListener(\r\n-        'partialResults',\r\n-        (data: { matches: string[] }) => {\r\n-          if (data.matches?.length) onTexto(data.matches[0])\r\n-        }\r\n-      )\r\n-    } else {\r\n-      try {\r\n-        const permissionStatus = await navigator.permissions?.query({\r\n-          name: 'microphone' as PermissionName,\r\n-        })\r\n-\r\n-        if (permissionStatus?.state === 'denied') {\r\n-          setErro('Permiss√£o de microfone negada pelo navegador. Verifique as configura√ß√µes do site.')\r\n-          return\r\n-        }\r\n-\r\n-        recognitionRef.current?.start()\r\n-      } catch (e) {\r\n-        setErro('Erro ao acessar o microfone. Verifique as permiss√µes do navegador.')\r\n-      }\r\n-    }\r\n-\r\n-    setGravando(true)\r\n-    gravandoRef.current = true\r\n-  }\r\n-\r\n-  const stop = async () => {\r\n-    if (platform === 'android' || platform === 'ios') {\r\n-      await SpeechRecognition.stop()\r\n-\r\n-      if (partialListenerRef.current) {\r\n-        await partialListenerRef.current.remove()\r\n-        partialListenerRef.current = null\r\n-      }\r\n-\r\n-      await SpeechRecognition.removeAllListeners()\r\n-    } else {\r\n-      recognitionRef.current?.stop?.()\r\n-    }\r\n-\r\n-    setGravando(false)\r\n-    gravandoRef.current = false\r\n-  }\r\n-\r\n-  return {\r\n-    gravando,\r\n-    erro,\r\n-    start,\r\n-    stop,\r\n-  }\r\n-}\r\n"
                },
                {
                    "date": 1747776928016,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,14 +16,8 @@\n     readonly resultIndex: number // üëà adicione isso\r\n   }\r\n }\r\n \r\n-/**\r\n- * Op√ß√µes do hook useSpeechRecognition\r\n- */\r\n-interface UseSpeechRecognitionOptions {\r\n-  onTexto: (texto: string) => void\r\n-}\r\n \r\n /**\r\n  * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n  */\r\n"
                },
                {
                    "date": 1747777004447,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,13 +54,8 @@\n     recognition.onerror = (e: any) => {\r\n       setErro('Erro no reconhecimento de voz: ' + e.error)\r\n     }\r\n \r\n-    recognition.onend = () => {\r\n-      if (gravandoRef.current) {\r\n-        setTimeout(() => recognition.start(), 100)\r\n-      }\r\n-    }\r\n \r\n     recognitionRef.current = recognition\r\n   }, [])\r\n \r\n"
                },
                {
                    "date": 1747778112503,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,9 +20,9 @@\n \r\n /**\r\n  * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n  */\r\n-export function useSpeechRecognition() {\r\n+export function useSpeechRecognition(p0?: { onTexto: (textoReconhecido: any) => void }) {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n   const [texto, setTexto] = useState('')\r\n \r\n@@ -47,9 +47,9 @@\n     recognition.interimResults = true\r\n \r\n     recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n       const novo = e.results[e.resultIndex][0].transcript\r\n-      setTexto((prev) => `${prev} ${novo}`.trim())\r\n+      setTexto(novo.trim())\r\n     }\r\n \r\n     recognition.onerror = (e: any) => {\r\n       setErro('Erro no reconhecimento de voz: ' + e.error)\r\n"
                },
                {
                    "date": 1747778193566,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,8 +46,12 @@\n     recognition.continuous = true\r\n     recognition.interimResults = true\r\n \r\n     recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n+       const txt = Array.from(event.results)\r\n+          .map(r => r[0].transcript)\r\n+          .join(' ');\r\n+      console.info('debug texto: ', txt)\r\n       const novo = e.results[e.resultIndex][0].transcript\r\n       setTexto(novo.trim())\r\n     }\r\n \r\n"
                },
                {
                    "date": 1747778199410,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,9 +46,9 @@\n     recognition.continuous = true\r\n     recognition.interimResults = true\r\n \r\n     recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-       const txt = Array.from(event.results)\r\n+       const txt = Array.from(e.results)\r\n           .map(r => r[0].transcript)\r\n           .join(' ');\r\n       console.info('debug texto: ', txt)\r\n       const novo = e.results[e.resultIndex][0].transcript\r\n"
                },
                {
                    "date": 1747778456681,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,9 +20,9 @@\n \r\n /**\r\n  * Hook React para reconhecimento de voz (Web/Android/iOS)\r\n  */\r\n-export function useSpeechRecognition(p0?: { onTexto: (textoReconhecido: any) => void }) {\r\n+export function useSpeechRecognition() {\r\n   const [gravando, setGravando] = useState(false)\r\n   const [erro, setErro] = useState<string | null>(null)\r\n   const [texto, setTexto] = useState('')\r\n \r\n"
                },
                {
                    "date": 1747778466518,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,11 +46,11 @@\n     recognition.continuous = true\r\n     recognition.interimResults = true\r\n \r\n     recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n-       const txt = Array.from(e.results)\r\n-          .map(r => r[0].transcript)\r\n-          .join(' ');\r\n+      const txt = Array.from(e.results)\r\n+        .map(r => r[0].transcript)\r\n+        .join(' ');\r\n       console.info('debug texto: ', txt)\r\n       const novo = e.results[e.resultIndex][0].transcript\r\n       setTexto(novo.trim())\r\n     }\r\n"
                },
                {
                    "date": 1747778498596,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -58,9 +58,8 @@\n     recognition.onerror = (e: any) => {\r\n       setErro('Erro no reconhecimento de voz: ' + e.error)\r\n     }\r\n \r\n-\r\n     recognitionRef.current = recognition\r\n   }, [])\r\n \r\n   const start = async () => {\r\n"
                },
                {
                    "date": 1747778507482,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,8 +132,8 @@\n     erro,\r\n     gravando,\r\n     start,\r\n     stop,\r\n-    setTexto, // opcional, se quiser permitir reset manual\r\n+    setTexto, \r\n   }\r\n }\r\n \r\n"
                },
                {
                    "date": 1747779086570,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -51,9 +51,9 @@\n         .map(r => r[0].transcript)\r\n         .join(' ');\r\n       console.info('debug texto: ', txt)\r\n       const novo = e.results[e.resultIndex][0].transcript\r\n-      setTexto(novo.trim())\r\n+      setTexto((prev) => prev+novo.trim())\r\n     }\r\n \r\n     recognition.onerror = (e: any) => {\r\n       setErro('Erro no reconhecimento de voz: ' + e.error)\r\n"
                },
                {
                    "date": 1747779105718,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -51,9 +51,9 @@\n         .map(r => r[0].transcript)\r\n         .join(' ');\r\n       console.info('debug texto: ', txt)\r\n       const novo = e.results[e.resultIndex][0].transcript\r\n-      setTexto((prev) => prev+novo.trim())\r\n+      setTexto((prev) => prev+' '+novo.trim())\r\n     }\r\n \r\n     recognition.onerror = (e: any) => {\r\n       setErro('Erro no reconhecimento de voz: ' + e.error)\r\n"
                },
                {
                    "date": 1747779111581,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -51,9 +51,9 @@\n         .map(r => r[0].transcript)\r\n         .join(' ');\r\n       console.info('debug texto: ', txt)\r\n       const novo = e.results[e.resultIndex][0].transcript\r\n-      setTexto((prev) => prev+' '+novo.trim())\r\n+      setTexto((prev) => prev + ' ' + novo.trim())\r\n     }\r\n \r\n     recognition.onerror = (e: any) => {\r\n       setErro('Erro no reconhecimento de voz: ' + e.error)\r\n"
                },
                {
                    "date": 1747779202286,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,11 +49,10 @@\n     recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n       const txt = Array.from(e.results)\r\n         .map(r => r[0].transcript)\r\n         .join(' ');\r\n-      console.info('debug texto: ', txt)\r\n-      const novo = e.results[e.resultIndex][0].transcript\r\n-      setTexto((prev) => prev + ' ' + novo.trim())\r\n+\r\n+      setTexto(txt)\r\n     }\r\n \r\n     recognition.onerror = (e: any) => {\r\n       setErro('Erro no reconhecimento de voz: ' + e.error)\r\n"
                }
            ],
            "date": 1747763144666,
            "name": "Commit-0",
            "content": "import { useEffect, useRef, useState } from 'react'\r\nimport { Capacitor } from '@capacitor/core'\r\nimport { SpeechRecognition } from '@capacitor-community/speech-recognition'\r\n\r\n/**\r\n * Declara√ß√µes globais necess√°rias para usar a API Web Speech\r\n */\r\ndeclare global {\r\n  interface Window {\r\n    webkitSpeechRecognition: any\r\n    SpeechRecognition: any\r\n  }\r\n\r\n  interface SpeechRecognitionEvent extends Event {\r\n    readonly results: SpeechRecognitionResultList\r\n  }\r\n}\r\n\r\n/**\r\n * Op√ß√µes do hook useSpeechRecognition\r\n * @property onTexto - Fun√ß√£o chamada sempre que um novo trecho de texto for reconhecido\r\n */\r\nexport interface UseSpeechRecognitionOptions {\r\n  onTexto: (texto: string) => void\r\n}\r\n\r\n/**\r\n * Hook React para reconhecimento de voz multiplataforma (Web, Android, iOS).\r\n * \r\n * - Usa Web Speech API no navegador\r\n * - Usa plugin do Capacitor em dispositivos m√≥veis\r\n * - Detecta plataforma automaticamente\r\n * \r\n * @param {UseSpeechRecognitionOptions} options - Op√ß√µes de configura√ß√£o, incluindo o callback `onTexto`\r\n * @returns Um objeto com estado de grava√ß√£o, erros e fun√ß√µes para iniciar/parar o reconhecimento\r\n * \r\n * @example\r\n * ```tsx\r\n * const { gravando, start, stop, erro } = useSpeechRecognition({ onTexto: (t) => console.log(t) })\r\n * ```\r\n */\r\nexport function useSpeechRecognition({ onTexto }: UseSpeechRecognitionOptions) {\r\n  const [gravando, setGravando] = useState(false)\r\n  const [erro, setErro] = useState<string | null>(null)\r\n  const recognitionRef = useRef<any>(null)\r\n  const platform = Capacitor.getPlatform()\r\n\r\n  useEffect(() => {\r\n    if (platform === 'web') {\r\n      const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition\r\n      if (!SpeechRecognitionClass) {\r\n        setErro('Reconhecimento de voz n√£o suportado no navegador.')\r\n        return\r\n      }\r\n\r\n      const recognition = new SpeechRecognitionClass()\r\n      recognition.lang = 'pt-BR'\r\n      recognition.continuous = true\r\n      recognition.interimResults = true\r\n\r\n      recognition.onresult = (e: SpeechRecognitionEvent) => {\r\n        const texto = Array.from(e.results)\r\n          .map((r) => r[0].transcript)\r\n          .join(' ')\r\n        onTexto(texto)\r\n      }\r\n\r\n      recognition.onerror = (e: any) => {\r\n        setErro('Erro no reconhecimento de voz: ' + e.error)\r\n      }\r\n\r\n      recognition.onend = () => {\r\n        if (recognitionRef.current && gravando) {\r\n          recognitionRef.current.start()\r\n        }\r\n      }\r\n\r\n      recognitionRef.current = recognition\r\n    }\r\n\r\n    return () => {\r\n      recognitionRef.current?.stop?.()\r\n    }\r\n  }, [platform, onTexto, gravando])\r\n\r\n  /**\r\n   * Inicia o reconhecimento de voz com base na plataforma\r\n   */\r\n  const start = async () => {\r\n    setErro(null)\r\n\r\n    if (platform === 'android' || platform === 'ios') {\r\n      const { speechRecognition } = await SpeechRecognition.requestPermissions()\r\n      if (speechRecognition !== 'granted') {\r\n        setErro('Permiss√£o negada para usar o microfone.')\r\n        return\r\n      }\r\n\r\n      await SpeechRecognition.start({\r\n        language: 'pt-BR',\r\n        partialResults: true,\r\n        popup: false,\r\n      })\r\n\r\n      SpeechRecognition.addListener('partialResults', (data: { matches: string[] }) => {\r\n        if (data.matches?.length) onTexto(data.matches[0])\r\n      })\r\n    } else {\r\n      try {\r\n        recognitionRef.current?.start()\r\n      } catch (e) {\r\n        setErro('Erro ao iniciar reconhecimento de voz.')\r\n      }\r\n    }\r\n\r\n    setGravando(true)\r\n  }\r\n\r\n  /**\r\n   * Encerra o reconhecimento de voz e limpa listeners\r\n   */\r\n  const stop = async () => {\r\n    if (platform === 'android' || platform === 'ios') {\r\n      await SpeechRecognition.stop()\r\n      await SpeechRecognition.removeAllListeners()\r\n    } else {\r\n      recognitionRef.current?.stop?.()\r\n    }\r\n\r\n    setGravando(false)\r\n  }\r\n\r\n  return {\r\n    gravando,\r\n    erro,\r\n    start,\r\n    stop,\r\n  }\r\n}\r\n"
        }
    ]
}